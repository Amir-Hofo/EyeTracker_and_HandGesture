{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m_TZq5ioC7za"
   },
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GaON7XblC0da"
   },
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from cvzone.FaceDetectionModule import FaceDetector\n",
    "from cvzone.FaceMeshModule import FaceMeshDetector\n",
    "from cvzone.HandTrackingModule import HandDetector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34bsFdl6EN5g"
   },
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mCCUQLyWEPOg"
   },
   "source": [
    "# Eye Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "tqCDAuA_LG0J"
   },
   "outputs": [],
   "source": [
    "LEFT_EYE=[362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398]\n",
    "RIGHT_EYE= [155, 154, 153, 145, 144, 163, 7, 33, 246, 161, 160, 159, 158, 159, 173, 133]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facedetector object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "njhHfkAFEOwo"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1740231350.674320  175487 gl_context.cc:369] GL version: 2.1 (2.1 INTEL-10.4.14), renderer: Intel HD Graphics 3000 OpenGL Engine\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1740231350.693157  175796 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1740231350.738140  175487 gl_context.cc:369] GL version: 2.1 (2.1 INTEL-10.4.14), renderer: Intel HD Graphics 3000 OpenGL Engine\n",
      "W0000 00:00:1740231350.761288  175807 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740231350.791933  175809 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "I0000 00:00:1740231350.809041  175487 gl_context.cc:369] GL version: 2.1 (2.1 INTEL-10.4.14), renderer: Intel HD Graphics 3000 OpenGL Engine\n"
     ]
    }
   ],
   "source": [
    "face_detector= FaceDetector()\n",
    "meshdetector= FaceMeshDetector(maxFaces=1)\n",
    "hands_detector= HandDetector(detectionCon = 0.5, maxHands=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZBSsV3aDpZr"
   },
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXY8-GijDCzD"
   },
   "source": [
    "# Select video file or webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPczj0asDECL",
    "outputId": "6935588b-f3bd-4342-fd96-f71b017d34f4"
   },
   "outputs": [],
   "source": [
    "webcam= True\n",
    "video_path= 'video.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740231350.957029  175817 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1740231351.030751  175817 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "if webcam:\n",
    "    cap= cv.VideoCapture(0)\n",
    "else:\n",
    "    cap= cv.VideoCapture(video_path)\n",
    "\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDVsBVzrMPk9"
   },
   "source": [
    "# Run program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740231353.329492  175809 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    }
   ],
   "source": [
    "while cap.isOpened():\n",
    "    ret, frame= cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_eye= frame.copy()\n",
    "    face_img, bbox= face_detector.findFaces(frame_eye)\n",
    "    face_img, faces= meshdetector.findFaceMesh(frame_eye)\n",
    "    hand, frame= hands_detector.findHands(frame)\n",
    "\n",
    "    if hand:\n",
    "        hand1= hand[0]\n",
    "        lmlist1= hand1[\"lmList\"]\n",
    "        length, info, frame= hands_detector.findDistance(lmlist1[8][:-1], lmlist1[4][:-1], frame)\n",
    "        if len(hand)> 1:\n",
    "            hand2= hand[1]\n",
    "            lmlist2= hand2[\"lmList\"]\n",
    "            length, info, frame= hands_detector.findDistance(lmlist2[8][:-1], lmlist2[4][:-1], frame)\n",
    " \n",
    "    if bbox:\n",
    "        center = bbox[0][\"center\"]\n",
    "        if faces:\n",
    "            text= [\" \", \" \"]\n",
    "            for i, eye in enumerate([LEFT_EYE, RIGHT_EYE]):\n",
    "                eye_points = np.array([[faces[0][p][0], faces[0][p][1]] for p in eye])\n",
    "                (ex, ey, ew, eh) = cv.boundingRect(eye_points)\n",
    "                eye_roi = frame_eye[ey:ey+eh, ex:ex+ew]\n",
    "                eye_roi_gr = cv.cvtColor(eye_roi, cv.COLOR_BGR2GRAY)\n",
    "                _, iris = cv.threshold(eye_roi_gr, 40, 255, cv.THRESH_BINARY_INV)\n",
    "                contours, _ = cv.findContours(iris, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)\n",
    "                contours = sorted(contours, key=lambda x: cv.contourArea(x), reverse=True)\n",
    "\n",
    "                if contours:\n",
    "                    (ix, iy, iw, ih) = cv.boundingRect(contours[0])\n",
    "                    ix_cntr, iy_centr = ix + int(iw/2) + ex, iy + int(ih/2) + ey\n",
    "                    cv.circle(frame, (ix_cntr, iy_centr), 5, (0, 255, 0), -1)\n",
    "                    \n",
    "                    ix_cntr_e = ix + int(iw/2)\n",
    "                    if ix_cntr_e > int(3*ew/5):\n",
    "                        text[i]= \"left\"\n",
    "                    elif ix_cntr_e < int(2*ew/5):\n",
    "                        text[i]= \"right\"\n",
    "                    else:\n",
    "                        text[i]= \"center\"\n",
    "\n",
    "            text= f\"Left eye: {text[0]}, Right eye: {text[1]}\"\n",
    "            (w, h), _ = cv.getTextSize(text, cv.FONT_HERSHEY_PLAIN, 3, 2)\n",
    "            cv.rectangle(frame, (100, 100 - h), (100 + w, 100 + h), (0, 60, 0), -1)\n",
    "            cv.putText(frame, text, (100, 100), cv.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 2)\n",
    "\n",
    "    cv.imshow('Combined Tracking', frame)\n",
    "\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
